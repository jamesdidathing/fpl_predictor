{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pulp\n",
    "\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = 'data/'\n",
    "\n",
    "players_1617_df = pd.read_csv(folderpath+'2016-17/players_raw.csv')\n",
    "players_1718_df = pd.read_csv(folderpath+'2017-18/players_raw.csv')\n",
    "players_1819_df = pd.read_csv(folderpath+'2018-19/players_raw.csv')\n",
    "players_1920_df = pd.read_csv(folderpath+'2019-20/players_raw.csv')\n",
    "players_2021_df = pd.read_csv(folderpath+'2020-21/players_raw.csv')\n",
    "players_2122_df = pd.read_csv(folderpath+'2021-22/players_raw.csv')\n",
    "players_2223_df = pd.read_csv(folderpath+'2022-23/players_raw.csv')\n",
    "players_2324_df = pd.read_csv(folderpath+'2023-24/players_raw.csv')\n",
    "\n",
    "gws_1617_df = pd.read_csv(folderpath+'2016-17/gws/merged_gw.csv', encoding='latin')\n",
    "gws_1718_df = pd.read_csv(folderpath+'2017-18/gws/merged_gw.csv', encoding='latin')\n",
    "gws_1819_df = pd.read_csv(folderpath+'2018-19/gws/merged_gw.csv', encoding='latin')\n",
    "gws_1920_df = pd.read_csv(folderpath+'2019-20/gws/merged_gw.csv', encoding='latin')\n",
    "gws_2021_df = pd.read_csv(folderpath+'2020-21/gws/merged_gw.csv', encoding='latin')\n",
    "gws_2122_df = pd.read_csv(folderpath+'2021-22/gws/merged_gw.csv', encoding='latin')\n",
    "gws_2223_df = pd.read_csv(folderpath+'2022-23/gws/merged_gw.csv', encoding='latin')\n",
    "gws_2324_df = pd.read_csv(folderpath+'2023-24/gws/merged_gw.csv', encoding='latin')\n",
    "\n",
    "team_codes_df = pd.read_csv(folderpath+'teams.csv')\n",
    "team_codes_df.columns.values[2:] = team_codes_df.columns[2:].str.replace('team_', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and process the dataframes\n",
    "\n",
    "We want to add:\n",
    "- Player Position\n",
    "- Full Name (names are inconsistent across seasons and between df's)\n",
    "\n",
    "We will also remove `Danny Ward` as there were two in the 18/19 season, both has 0 points so no harm in removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Danny Wards from 18/19 season\n",
    "players_1819_df = players_1819_df[((players_1819_df.first_name == \"Danny\") & (players_1819_df.second_name==\"Ward\"))==False]\n",
    "gws_1819_df = gws_1819_df[gws_1819_df.name.str.contains(\"Danny_Ward\")==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are adding the seasons onto the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df_list = [players_1617_df, players_1718_df, players_1819_df, players_1920_df, players_2021_df, players_2122_df, players_2223_df, players_2324_df]\n",
    "gw_df_list = [gws_1617_df, gws_1718_df, gws_1819_df, gws_1920_df, gws_2021_df, gws_2122_df, gws_2223_df, gws_2324_df]\n",
    "\n",
    "# append season and season index to dfs\n",
    "\n",
    "seasons = ['1617', '1718', '1819', '1920', '2021', '2122', '2223', '2324']\n",
    "season_nums = list(range(len(seasons)))\n",
    "\n",
    "for i in range(len(seasons)):\n",
    "    player_df_list[i]['season'] = seasons[i]\n",
    "    gw_df_list[i]['season'] = seasons[i]\n",
    "    \n",
    "    player_df_list[i]['season_num'] = season_nums[i]\n",
    "    gw_df_list[i]['season_num'] = season_nums[i]\n",
    "\n",
    "# combine dataframes from all seasons into one\n",
    "\n",
    "players_df = pd.concat(player_df_list)\n",
    "gws_df = pd.concat(gw_df_list)\n",
    "players_df.reset_index(inplace=True)\n",
    "gws_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply a function to sort out the full names of the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_name_playerdf(first_name, second_name):\n",
    "    '''Creates full name, cleans up accents and makes processing easier'''\n",
    "\n",
    "    full_name = first_name +'_' + second_name\n",
    "    full_name = full_name.replace(\" \", \"_\")\n",
    "    full_name = full_name.replace(\"-\", \"_\")\n",
    "    full_name = unidecode.unidecode(full_name)\n",
    "    \n",
    "    return full_name\n",
    "\n",
    "# Translate player positions into string for easier readability\n",
    "positions_dict = {\n",
    "    1: 'Keeper',\n",
    "    2: 'Defender',\n",
    "    3: 'Midfielder',\n",
    "    4: 'Forward'\n",
    "    \n",
    "}\n",
    "\n",
    "# Now apply full name and position changes. We also add the starting cost by a simple subtraction of two existing data columns.\n",
    "players_df['full_name'] = players_df.apply(lambda x: get_full_name_playerdf(x.first_name, x.second_name), axis=1).str.lower()\n",
    "players_df['position'] = players_df.element_type.map(positions_dict)\n",
    "players_df['starting_cost'] = players_df.now_cost - players_df.cost_change_start_fall\n",
    "players_df['cost_bin'] = players_df.now_cost.apply(lambda x: np.floor(x/10))\n",
    "\n",
    "gws_df['full_name'] = gws_df.name.str.replace('_\\d+','')\n",
    "gws_df['full_name'] = gws_df['full_name'].str.replace(\" \", \"_\").str.replace(\"-\", \"_\").str.replace('_\\d+','')\n",
    "gws_df['full_name'] = gws_df['full_name'].apply(lambda x: unidecode.unidecode(x))\n",
    "gws_df['full_name'] = gws_df['full_name'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives us a df that contains all the GW info, plus info on the players team names and opponents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gw_df(player_df, gw_df, team_codes_df):\n",
    "    '''\n",
    "    Cleans and merges gameweek data with player information and team codes to return a DataFrame \n",
    "    containing player positions, player's team names, and opponent's team names.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the original gameweek data enriched with player positions, \n",
    "                player's team names, and opponent's team names.\n",
    "    '''\n",
    "\n",
    "    pdf = player_df.copy()[['full_name', 'season', 'position', 'player_team_name']]\n",
    "    gdf = gw_df.copy()\n",
    "    gdf = gdf.merge(pdf, on=['full_name', 'season'], how='left')\n",
    "    \n",
    "    dfs = []\n",
    "    for s, group in gdf.groupby('season'):\n",
    "\n",
    "        temp_code_df = team_codes_df[['team', s]]\n",
    "        temp_code_df = temp_code_df.dropna()\n",
    "        \n",
    "        group = group[['opponent_team']]\n",
    "        group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
    "        dfs.append(group[['opponent_team_name']])\n",
    "        \n",
    "    out_df = pd.concat(dfs, axis=0)\n",
    "    out_df = pd.concat([gdf, out_df], axis=1)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we apply the above to gather the opponent and player teams to the GW dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
      "/var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/ipykernel_22838/3669575184.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n"
     ]
    }
   ],
   "source": [
    "gws_df.opponent_team = gws_df.opponent_team.astype(float)\n",
    "players_df['player_team_name'] = players_df.team_code.map(team_codes_df.set_index('team_code').team)\n",
    "gws_df = clean_gw_df(players_df, gws_df, team_codes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "Now we move onto building the best team. There are a variety of rules with FPL with waht team you can build, which will be accounted for. \n",
    "\n",
    "We will use a simple model to pick the initial team, and then more complicated ones to decide on transfers etc. We will use the 23-24 season as our test set to test the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Team\n",
    "\n",
    "We will look at the latest season (22-23) (as our test set will be 23-24 season results) as the basis for the initial team, optimising fo the maximum number of points scored. As per FPL rules, we have the following rules:\n",
    "\n",
    "- Total budget of 1000\n",
    "- 1 keeper\n",
    "- 4 defenders\n",
    "- 4 midfielders\n",
    "- 2 forwards\n",
    "- No more than 3 players from each team\n",
    "\n",
    "Bench players are not considered much, and will be picked by the cheapest options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first get the players are who are available, as some would have been relegated after the previous season (and transferred etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_available_players_df(this_season_player_df, last_season_player_df):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame of available players for the current season by merging current season \n",
    "    player data with their total points from the previous season. If a player did not play \n",
    "    last season, their total points are filled with the average total points of players in \n",
    "    the same position and cost bin.\n",
    "\n",
    "    Parameters:\n",
    "    this_season_player_df (pd.DataFrame): DataFrame containing player data for the current season.\n",
    "    last_season_player_df (pd.DataFrame): DataFrame containing player data for the previous season, \n",
    "                                        including their total points.\n",
    "    \"\"\"\n",
    "\n",
    "    last_season_player_df = last_season_player_df[last_season_player_df.minutes > 0]\n",
    "    last_season_player_df = last_season_player_df[['full_name', \"total_points\"]]\n",
    "    last_season_player_df.rename(columns={'total_points': \"total_points_last_season\"},\n",
    "                                inplace=True)\n",
    "    \n",
    "    available_players_df = pd.merge(this_season_player_df,\n",
    "                                    last_season_player_df,\n",
    "                                    on='full_name', how='left')\n",
    "    \n",
    "    available_players_df.total_points_last_season = available_players_df.groupby(['position', 'cost_bin']).total_points_last_season.transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    return available_players_df\n",
    "\n",
    "# There are two Ben Davies, one plays for Liverpool and got 0 points so removing here, also\n",
    "# Kane was still in the df for some reason\n",
    "current_season_player_df = players_df[(players_df.season == '1920') &\n",
    "                                      ~((players_df.full_name == 'ben_davies') &\n",
    "                                        (players_df.player_team_name == 'Liverpool'))]\n",
    "\n",
    "current_season_player_df = players_df[(players_df.season == '1920') &\n",
    "                                      ~((players_df.full_name == 'harry_kane'))]\n",
    "\n",
    "previous_season_player_df = players_df[(players_df.season == '1819') &\n",
    "                                       ~((players_df.full_name == 'ben_davies') &\n",
    "                                         (players_df.player_team_name == 'Liverpool'))]\n",
    "\n",
    "available_players_df = make_available_players_df(current_season_player_df, previous_season_player_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the cheapest players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defender :  daryl_janmaat\n",
      "Forward :  lys_mousset\n",
      "Keeper :  darren_randolph\n",
      "Midfielder :  matteo_guendouzi\n"
     ]
    }
   ],
   "source": [
    "def get_cheapest_players(player_df):\n",
    "    \"\"\"\n",
    "    Identifies the cheapest players by position and returns their names along with the total cost.\n",
    "\n",
    "    This function groups the players by their positions, finds the player(s) with the minimum starting \n",
    "    cost within each position, and then selects the player with the highest total points among those \n",
    "    cheapest players. It collects these players' names and calculates the total cost of these selected players.\n",
    "    \"\"\"\n",
    "\n",
    "    cheapest_player_names = []\n",
    "    total_cost = 0\n",
    "    for position, group in player_df.groupby('position'):\n",
    "        cheapest_players =  group[(group.starting_cost == group.starting_cost.min())]\n",
    "        top_cheapest_player = cheapest_players[cheapest_players.total_points == cheapest_players.total_points.max()]\n",
    "        \n",
    "        cheapest_player_name = top_cheapest_player.full_name.values[0]\n",
    "        \n",
    "        cheapest_player_names += [cheapest_player_name]\n",
    "        total_cost += top_cheapest_player.starting_cost.values[0]\n",
    "        print(position, \": \", cheapest_player_name )\n",
    "        \n",
    "    return cheapest_player_names, total_cost\n",
    "\n",
    "bench_players, bench_cost = get_cheapest_players(available_players_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are our bench players selected, now let's go for the starting 11. We are going to assume if they did well last season, they will do well this season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/pstanis/Documents/personal_projects/fpl_predictor/venv/lib/python3.11/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/6141784965fd4ad6bdef378812f365d2-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/s7/mksssm8112scb6_3__pw7kb00000gq/T/6141784965fd4ad6bdef378812f365d2-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 30 COLUMNS\n",
      "At line 4021 RHS\n",
      "At line 4047 BOUNDS\n",
      "At line 4713 ENDATA\n",
      "Problem MODEL has 25 rows, 665 columns and 1995 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 2161.18 - 0.00 seconds\n",
      "Cgl0003I 0 fixed, 1 tightened bounds, 0 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 25 rows, 596 columns (596 integer (558 of which binary)) and 1788 elements\n",
      "Cbc0038I Initial state - 2 integers unsatisfied sum - 0.588235\n",
      "Cbc0038I Pass   1: suminf.    0.11905 (2) obj. -2152.01 iterations 5\n",
      "Cbc0038I Pass   2: suminf.    0.00000 (0) obj. -1946.71 iterations 2\n",
      "Cbc0038I Solution found of -1946.71\n",
      "Cbc0038I Cleaned solution of -1946.71\n",
      "Cbc0038I Before mini branch and bound, 592 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 25 rows 596 columns, reduced to 1 rows 2 columns\n",
      "Cbc0038I Mini branch and bound improved solution from -1946.71 to -2152 (0.01 seconds)\n",
      "Cbc0038I Round again with cutoff of -2152.92\n",
      "Cbc0038I Reduced cost fixing fixed 581 variables on major pass 2\n",
      "Cbc0038I Pass   3: suminf.    0.16393 (2) obj. -2157.38 iterations 2\n",
      "Cbc0038I Pass   4: suminf.    0.25984 (2) obj. -2152.92 iterations 3\n",
      "Cbc0038I Pass   5: suminf.    0.86418 (4) obj. -2152.92 iterations 4\n",
      "Cbc0038I Pass   6: suminf.    0.58610 (4) obj. -2152.92 iterations 1\n",
      "Cbc0038I Pass   7: suminf.    1.32237 (4) obj. -2152.92 iterations 2\n",
      "Cbc0038I Pass   8: suminf.    0.05562 (2) obj. -2152.92 iterations 3\n",
      "Cbc0038I Pass   9: suminf.    0.05562 (2) obj. -2152.92 iterations 1\n",
      "Cbc0038I Pass  10: suminf.    0.50067 (4) obj. -2152.92 iterations 5\n",
      "Cbc0038I Pass  11: suminf.    0.16393 (2) obj. -2157.38 iterations 4\n",
      "Cbc0038I Pass  12: suminf.    0.25984 (2) obj. -2152.92 iterations 2\n",
      "Cbc0038I Pass  13: suminf.    0.34497 (4) obj. -2152.92 iterations 3\n",
      "Cbc0038I Pass  14: suminf.    1.35957 (4) obj. -2152.92 iterations 2\n",
      "Cbc0038I Pass  15: suminf.    1.35957 (4) obj. -2152.92 iterations 0\n",
      "Cbc0038I Pass  16: suminf.    0.65310 (2) obj. -2152.92 iterations 3\n",
      "Cbc0038I Pass  17: suminf.    0.65310 (2) obj. -2152.92 iterations 0\n",
      "Cbc0038I Pass  18: suminf.    0.65310 (2) obj. -2152.92 iterations 1\n",
      "Cbc0038I Pass  19: suminf.    0.25984 (2) obj. -2152.92 iterations 4\n",
      "Cbc0038I Pass  20: suminf.    1.40720 (4) obj. -2152.92 iterations 6\n",
      "Cbc0038I Pass  21: suminf.    0.95348 (4) obj. -2152.92 iterations 1\n",
      "Cbc0038I Pass  22: suminf.    1.32237 (4) obj. -2152.92 iterations 3\n",
      "Cbc0038I Pass  23: suminf.    0.05562 (2) obj. -2152.92 iterations 1\n",
      "Cbc0038I Pass  24: suminf.    0.05562 (2) obj. -2152.92 iterations 1\n",
      "Cbc0038I Pass  25: suminf.    0.05562 (2) obj. -2152.92 iterations 0\n",
      "Cbc0038I Pass  26: suminf.    0.05562 (2) obj. -2152.92 iterations 0\n",
      "Cbc0038I Pass  27: suminf.    0.65310 (2) obj. -2152.92 iterations 3\n",
      "Cbc0038I Pass  28: suminf.    0.16393 (2) obj. -2157.38 iterations 2\n",
      "Cbc0038I Pass  29: suminf.    0.25984 (2) obj. -2152.92 iterations 2\n",
      "Cbc0038I Pass  30: suminf.    0.35061 (4) obj. -2152.92 iterations 3\n",
      "Cbc0038I Pass  31: suminf.    0.53270 (4) obj. -2152.92 iterations 2\n",
      "Cbc0038I Pass  32: suminf.    0.22727 (2) obj. -2155.91 iterations 4\n",
      "Cbc0038I No solution found this major pass\n",
      "Cbc0038I Before mini branch and bound, 583 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 25 rows 596 columns, reduced to 3 rows 8 columns\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.01 seconds)\n",
      "Cbc0038I After 0.01 seconds - Feasibility pump exiting with objective of -2152 - took 0.01 seconds\n",
      "Cbc0012I Integer solution of -2152 found by feasibility pump after 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0031I 2 added rows had average density of 18.5\n",
      "Cbc0013I At root node, 2 cuts changed objective from -2161.1765 to -2159.6596 in 4 passes\n",
      "Cbc0014I Cut generator 0 (Probing) - 0 row cuts average 0.0 elements, 1 column cuts (1 active)  in 0.000 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 1 (Gomory) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 2 (Knapsack) - 3 row cuts average 18.7 elements, 0 column cuts (0 active)  in 0.001 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 3 (Clique) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 4 (MixedIntegerRounding2) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 5 (FlowCover) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0001I Search completed - best objective -2152, took 20 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0032I Strong branching done 2 times (1 iterations), fathomed 1 nodes and fixed 0 variables\n",
      "Cbc0035I Maximum depth 0, 544 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from -2161.18 to -2152.86\n",
      "Probing was tried 4 times and created 1 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 4 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 4 times and created 3 cuts of which 0 were active after adding rounds of cuts (0.001 seconds)\n",
      "Clique was tried 4 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 4 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 4 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                2152.00000000\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               20\n",
      "Time (CPU seconds):             0.02\n",
      "Time (Wallclock seconds):       0.02\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.02   (Wallclock seconds):       0.02\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>position</th>\n",
       "      <th>starting_cost</th>\n",
       "      <th>player_team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>andrew_robertson</td>\n",
       "      <td>Defender</td>\n",
       "      <td>70</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>aymeric_laporte</td>\n",
       "      <td>Defender</td>\n",
       "      <td>61</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>callum_wilson</td>\n",
       "      <td>Forward</td>\n",
       "      <td>68</td>\n",
       "      <td>Bournemouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>david_luiz_moreira_marinho</td>\n",
       "      <td>Defender</td>\n",
       "      <td>54</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>gylfi_sigurdsson</td>\n",
       "      <td>Midfielder</td>\n",
       "      <td>66</td>\n",
       "      <td>Everton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>jordan_pickford</td>\n",
       "      <td>Keeper</td>\n",
       "      <td>49</td>\n",
       "      <td>Everton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>mohamed_salah</td>\n",
       "      <td>Midfielder</td>\n",
       "      <td>125</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>pierre_emerick_aubameyang</td>\n",
       "      <td>Forward</td>\n",
       "      <td>108</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>raheem_sterling</td>\n",
       "      <td>Midfielder</td>\n",
       "      <td>120</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>ryan_fraser</td>\n",
       "      <td>Midfielder</td>\n",
       "      <td>61</td>\n",
       "      <td>Bournemouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>virgil_van_dijk</td>\n",
       "      <td>Defender</td>\n",
       "      <td>65</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      full_name    position  starting_cost player_team_name\n",
       "43             andrew_robertson    Defender             70        Liverpool\n",
       "69              aymeric_laporte    Defender             61  Manchester City\n",
       "107               callum_wilson     Forward             68      Bournemouth\n",
       "163  david_luiz_moreira_marinho    Defender             54          Arsenal\n",
       "243            gylfi_sigurdsson  Midfielder             66          Everton\n",
       "342             jordan_pickford      Keeper             49          Everton\n",
       "473               mohamed_salah  Midfielder            125        Liverpool\n",
       "534   pierre_emerick_aubameyang     Forward            108          Arsenal\n",
       "539             raheem_sterling  Midfielder            120  Manchester City\n",
       "571                 ryan_fraser  Midfielder             61      Bournemouth\n",
       "643             virgil_van_dijk    Defender             65        Liverpool"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions with additional checks for NaN values\n",
    "def make_decision_variables(player_df):\n",
    "    return [pulp.LpVariable(player, cat=\"Binary\") for player in player_df.full_name]\n",
    "\n",
    "def make_optimization_function(player_df, decision_variables):\n",
    "    op_func = pulp.lpSum(\n",
    "        0 if pd.isna(player_df.total_points_last_season[i]) else player_df.total_points_last_season[i] * decision_variables[i]\n",
    "        for i in range(len(player_df))\n",
    "    )\n",
    "    return op_func\n",
    "\n",
    "def make_cash_constraint(player_df, decision_variables, available_cash):\n",
    "    total_paid = pulp.lpSum(\n",
    "        0 if pd.isna(player_df.starting_cost[i]) else player_df.starting_cost[i] * decision_variables[i]\n",
    "        for i in range(len(player_df))\n",
    "    )\n",
    "    return (total_paid <= available_cash)\n",
    "\n",
    "def make_player_constraint(position, n, decision_variables, player_df):\n",
    "    total_n = pulp.lpSum(\n",
    "        decision_variables[i] for i in range(len(player_df)) if player_df.position[i] == position\n",
    "    )\n",
    "    return (total_n == n)\n",
    "\n",
    "def add_team_constraint(prob, player_df, decision_variables):\n",
    "    for team, group in player_df.groupby('team_code'):\n",
    "        team_total = pulp.lpSum(\n",
    "            decision_variables[i] for i in range(len(player_df)) if player_df.full_name[i] in group.full_name.values\n",
    "        )\n",
    "        prob += (team_total <= 3)\n",
    "\n",
    "available_cash = 1000 - bench_cost\n",
    "\n",
    "prob = pulp.LpProblem('InitialTeam', pulp.LpMaximize)\n",
    "\n",
    "decision_variables = make_decision_variables(available_players_df)\n",
    "prob += make_optimization_function(available_players_df, decision_variables)\n",
    "prob += make_cash_constraint(available_players_df, decision_variables, available_cash)\n",
    "prob += make_player_constraint(\"Keeper\", 1, decision_variables, available_players_df) \n",
    "prob += make_player_constraint(\"Defender\", 4, decision_variables, available_players_df) \n",
    "prob += make_player_constraint(\"Midfielder\", 4, decision_variables, available_players_df) \n",
    "prob += make_player_constraint(\"Forward\", 2, decision_variables, available_players_df)\n",
    "\n",
    "add_team_constraint(prob, available_players_df, decision_variables)\n",
    "\n",
    "## Solve\n",
    "\n",
    "prob.writeLP('InitialTeam.lp')\n",
    "optimization_result = prob.solve()\n",
    "\n",
    "## Get initial team\n",
    "\n",
    "def get_initial_team(prob, player_df):\n",
    "    \n",
    "    variable_names = [v.name for v in prob.variables()]\n",
    "    variable_values = [v.varValue for v in prob.variables()]\n",
    "\n",
    "    initial_team = pd.merge(pd.DataFrame({'full_name': variable_names,\n",
    "                  'selected': variable_values}),\n",
    "                                    player_df, on=\"full_name\")\n",
    "    \n",
    "    initial_team = initial_team[initial_team.selected==1.0] \n",
    "    return initial_team\n",
    "\n",
    "initial_team_df = get_initial_team(prob, available_players_df)\n",
    "initial_team_df[['full_name', \"position\", \"starting_cost\", \"player_team_name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the initial team\n",
    "\n",
    "Say we set and forget this team, how many points would it of got us? Really quite bad it turns out. \n",
    "\n",
    "- Ivan Toney was banned for a lot of the season\n",
    "- Martinelli barely started\n",
    "- Rashford wasn't on form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points for 23/24 season: 1792\n"
     ]
    }
   ],
   "source": [
    "captain = get_initial_team(prob, previous_season_player_df).sort_values(\"total_points\", ascending=False).head(1).full_name.values[0]\n",
    "\n",
    "captain = get_initial_team(prob, previous_season_player_df).sort_values(\"total_points\", ascending=False).head(1).full_name.values[0]\n",
    "\n",
    "total_points = current_season_player_df[current_season_player_df.full_name.isin(initial_team_df.full_name)].total_points.sum()\n",
    "total_points += current_season_player_df[current_season_player_df.full_name==captain].total_points\n",
    "\n",
    "print(\"Total points for 23/24 season:\", total_points.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling \n",
    "\n",
    "We will use both players previous performances and oppenent team performances.\n",
    "\n",
    "- Use previous Gameweek's performance to predict total points for next gameweek\n",
    "- Calculate a rolling average\n",
    "- Also use previous season's total points as a predictor, as the predictions for the earlier gameweeks might be extremely noisy. This is important as we don't want star players to be transfered out just because they had a bad start\n",
    "- For players without data from past seasons, replace with average of players in the same position and similar cost (rounded to nearest 10m)\n",
    "- Only include players who had played (i.e. minutes > 0) to reduce noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some functions to help us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the points from the players team\n",
    "def get_team_points(was_home, h_score, a_score):\n",
    "    if h_score == a_score:\n",
    "        return 1\n",
    "    \n",
    "    if h_score > a_score:\n",
    "        if was_home:\n",
    "            return 3\n",
    "        else: \n",
    "            return 0\n",
    "    \n",
    "    if h_score < a_score:\n",
    "        if was_home:\n",
    "            return 0\n",
    "        else: \n",
    "            return 3\n",
    "\n",
    "# Get the points from the opponents team\n",
    "def get_opponent_points(team_points):\n",
    "    if team_points == 1:\n",
    "        return 1\n",
    "    \n",
    "    if team_points == 3:\n",
    "        return 0\n",
    "    \n",
    "    if team_points == 0:\n",
    "        return 3\n",
    "\n",
    "# Using these functions, add the team points and opponent points to the dataframes for that gw \n",
    "gws_df['team_points']= gws_df.apply(lambda x: get_team_points(x.was_home, x.team_h_score, x.team_a_score), axis=1)\n",
    "gws_df['opponent_points'] = gws_df.team_points.apply(lambda x: get_opponent_points(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are lagged functions, which basically look at past games and creates lagged features for teams in the gameweek dataframe. We use this to have some predictive modelling, based on the last few games results.\n",
    "\n",
    "The 'lag' is the number of past gameweeks to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_lag_features(gw_df, features, lags):\n",
    "    out_df = gw_df.copy()\n",
    "    lagged_features = []\n",
    "\n",
    "    for feature in features:       \n",
    "        for lag in lags:      \n",
    "            lagged_feature = 'last_' + str(lag) + '_' + feature      \n",
    "            if lag == 'all':\n",
    "                out_df[lagged_feature] = out_df.sort_values('round').groupby(['season', 'full_name'], group_keys=False)[feature].apply(lambda x: x.cumsum() - x)   \n",
    "            else:\n",
    "                out_df[lagged_feature] = out_df.sort_values('round').groupby(['season', 'full_name'], group_keys=False)[feature].apply(lambda x: x.rolling(min_periods=1, window=lag+1).sum() - x)\n",
    "            lagged_features.append(lagged_feature)\n",
    "    return out_df, lagged_features\n",
    "\n",
    "def team_lag_features(gw_df, features, lags):\n",
    "    out_df = gw_df.copy()\n",
    "    lagged_features = []\n",
    "    \n",
    "    for feature in features:\n",
    "        ## Create a df for each feature\n",
    "        ## Then, self-join so that the opponent info for that feature is included\n",
    "        ## Then, create lagged features and join the columns to the feature df\n",
    "        ## Do the same for the opponent feature\n",
    "        ## Exit loop, merge with the original df\n",
    "        feature_name = feature + '_team'\n",
    "        opponent_feature_name = feature_name + '_opponent'\n",
    "        feature_team = out_df.groupby(['player_team_name', 'season', 'round', 'kickoff_time', 'opponent_team_name'])\\\n",
    "                        [feature].max().rename(feature_name).reset_index()\n",
    "        \n",
    "        # self join to get opponent info \n",
    "        feature_team = feature_team.merge(feature_team,\n",
    "                        left_on=['player_team_name', 'season', 'round', 'kickoff_time', 'opponent_team_name'],\n",
    "                        right_on=['opponent_team_name', 'season', 'round', 'kickoff_time', 'player_team_name'],\n",
    "                        how='left',\n",
    "                        suffixes=('', '_opponent'))\n",
    "            \n",
    "        for lag in lags:\n",
    "            lagged_feature_name = 'last_' + str(lag) + '_' + feature_name\n",
    "            lagged_opponent_feature_name = 'opponent_last_' + str(lag) + '_' + feature\n",
    "            \n",
    "            if lag == 'all':     \n",
    "                feature_team[lagged_feature_name] = feature_team.sort_values('round').groupby('player_team_name', group_keys=False)[feature_name]\\\n",
    "                                                    .apply(lambda x: x.cumsum() - x)\n",
    "                feature_team[lagged_opponent_feature_name] = feature_team.groupby('player_team_name', group_keys=False)[opponent_feature_name]\\\n",
    "                                                .apply(lambda x: x.cumsum() - x)\n",
    "            else:      \n",
    "                feature_team[lagged_feature_name] = feature_team.sort_values('round').groupby('player_team_name', group_keys=False)[feature_name]\\\n",
    "                                                    .apply(lambda x: x.rolling(min_periods=1,\n",
    "                                                                            window=lag+1).sum()-x)\n",
    "                feature_team[lagged_opponent_feature_name] = feature_team.groupby('player_team_name', group_keys=False)[opponent_feature_name]\\\n",
    "                                                    .apply(lambda x: x.rolling(min_periods=1,\n",
    "                                                                            window=lag+1).sum()-x)\n",
    "            lagged_features.extend([lagged_feature_name, lagged_opponent_feature_name])\n",
    "        out_df = out_df.merge(feature_team,\n",
    "                            on=['player_team_name', 'season', 'round', 'kickoff_time', 'opponent_team_name'],\n",
    "                            how='left')        \n",
    "        return out_df, lagged_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of the features we want to lag a.k.a look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features_to_lag = [\n",
    "    'assists',\n",
    "    'bonus',\n",
    "    'bps',\n",
    "    'creativity',\n",
    "    'clean_sheets',\n",
    "    'goals_conceded',\n",
    "    'goals_scored',\n",
    "    'ict_index',\n",
    "    'influence',\n",
    "    'minutes',\n",
    "    'threat']\n",
    "\n",
    "team_features_to_lag = ['goals_conceded', 'goals_scored', 'team_points', 'opponent_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_gw_df_players, lagged_player_features = player_lag_features(gws_df, player_features_to_lag, ['all', 1, 3, 5])\n",
    "\n",
    "lagged_gw_df, lagged_team_features = team_lag_features(lagged_gw_df_players, team_features_to_lag, ['all', 1, 3, 5])\n",
    "\n",
    "relevant_features = ['position_y', 'was_home', 'minutes', 'value', 'round', 'season_num'] + \\\n",
    "    lagged_player_features + \\\n",
    "    lagged_team_features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts the numerical (numbers) and categorical (everything else) features from our dataframe. We convert the categorical data into as many 0/1 values as there are differect values using `get_dummies` from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(df, numerical_features, categorical_features):\n",
    "    X_num = df[numerical_features]\n",
    "    X_cat = df[categorical_features]\n",
    "    \n",
    "    X_cat = X_cat.astype(str)\n",
    "    X_cat = pd.get_dummies(X_cat)\n",
    "    \n",
    "    # Join categorical and numerical features\n",
    "    X = pd.concat([X_num, X_cat], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define which features are categorical and which are numerical. \n",
    "\n",
    "After that we split the dataset into training and testing sets based on the season. Training is everything BUT 1920 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['was_home', 'position_y']\n",
    "numerical_features = numerical_features = list(set(relevant_features) - set(categorical_features))\n",
    "\n",
    "train_df = lagged_gw_df[(lagged_gw_df.season!='1920')]\n",
    "test_df = lagged_gw_df[(lagged_gw_df.season=='1920') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we quickly remove any NA values from in specific columns and clean the testing and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost handles NA values, but the other scikit learn methods (that I've chosen) do not\n",
    "lagged_gw_df_no_na = lagged_gw_df.dropna(subset=relevant_features + ['total_points', 'season'])\n",
    "train_df_no_na = lagged_gw_df_no_na[lagged_gw_df_no_na.season!='1920']\n",
    "test_df_no_na = lagged_gw_df_no_na[lagged_gw_df_no_na.season=='1920']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply make_dummies to the training and testing sets to handle categorical variables.\n",
    "- Extract the target variable (total_points) for both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = make_dummies(train_df[relevant_features], numerical_features, categorical_features)\n",
    "y_train = train_df.total_points\n",
    "\n",
    "X_train_no_na = make_dummies(train_df_no_na[relevant_features], numerical_features, categorical_features)\n",
    "y_train_no_na = train_df_no_na.total_points\n",
    "\n",
    "X_test = make_dummies(test_df, numerical_features, categorical_features)\n",
    "y_test = test_df.total_points\n",
    "\n",
    "X_test_no_na = make_dummies(test_df_no_na, numerical_features, categorical_features)\n",
    "y_test_no_na = test_df_no_na.total_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "\n",
    "We will look at the following:\n",
    "- Linear regression\n",
    "- XGBoost\n",
    "- A baseline model using group means\n",
    "\n",
    "All models will be compared and the top 2 (with the highest cross-validation score -  RMSE) will be used to make predictions to be fed into the algorithm to select potential transfers for each gameweek. The RMSE (root-mean square method) compares the predicted values to real values to test how well the model performed. \n",
    "\n",
    "A brief explanation on the starting values I have selected for the tuning of the hyperparameters for the XGBoost model:\n",
    "\n",
    "`max_depth`: larger values makes the model (1) more complex, (2) more likely to overfit, and (3) take longer to train. Here, we used a range from 3-6 (the default). Wary of overfitting since the nature of the data can change dramatically across seasons (e.g. due to player transfers, improvement/decline of play abilities, state of the club etc.).\n",
    "\n",
    "`min_child_weight`: Similar to max_depth, we want to reduce the complexity/variance in the model. Here, larger values will reduce the likelihood of overfitting. decided to use a range from 6-10\n",
    "\n",
    "`learning_rate`: The default here is 0.3. decided to try 5 values: 1/10 of the default, 1/5 of the default, 1.5x the default, and 2x the default.\n",
    "\n",
    "`subsample and colsample_by_tree`: The default here is 1, but since we want to reduce overfitting, we decided to use a range from 0.8 - 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=37, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=37, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=37, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': list(range(3,7)),  \n",
    "    'min_child_weight': list(range(10,51)),\n",
    "    'learning_rate':  [0.03, 0.15, 0.3, 0.45, 0.6],\n",
    "    'subsample': stats.uniform(0.8, 0.1),\n",
    "    'colsample_bytree': [0.8, 0.1]}\n",
    "\n",
    "# Initial XGBoost regressor and fit it to the training data\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# This is to find the best hyperparamaters by trying various combinations of values that we specified above\n",
    "xgb_cv = RandomizedSearchCV(xgb_reg, params, cv=3, scoring='neg_root_mean_squared_error',\n",
    "                            random_state=999)\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "\n",
    "# Here we create a new XGBoost model, using the best paramaters that we found from the above randomized search.\n",
    "xgb_best = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgb_best.set_params(**xgb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the other models we want to try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 999\n",
    "models = []\n",
    "models.append(('LinReg', LinearRegression()))\n",
    "models.append(('LassoReg', LassoCV()))\n",
    "models.append(('RidgeReg', RidgeCV()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function just returns the RMSE values for each of the models, to see which one is best to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_scores(models, X, y, k=5, seed=999):\n",
    "    # inspired by the excellent tutorial by Jason Brownlee:\n",
    "    # https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "    names = []\n",
    "    results = []\n",
    "    print(\"Cross val scores:\")\n",
    "    \n",
    "    for name, m in models:\n",
    "        cv_results = -cross_val_score(m, X, y, cv=k, scoring='neg_root_mean_squared_error')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        \n",
    "        print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std() ))\n",
    "        print(\"\")\n",
    "        print(\"*\"*88)\n",
    "        print(\"\")  \n",
    "    return names, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then finally, we just run this for all of our models (including XGBoost with the best paramaters as we have found above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val scores:\n",
      "LinReg: 1.812949 (0.066013)\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "LassoReg: 1.816816 (0.067618)\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "RidgeReg: 1.812961 (0.066011)\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "Cross val scores:\n",
      "XGB: 1.796788 (0.074906)\n",
      "\n",
      "****************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names, model_results = get_cv_scores(models, X_train_no_na, y_train_no_na)\n",
    "\n",
    "xgb_cv_scores = get_cv_scores([(\"XGB\", xgb_best)], X_train, y_train)\n",
    "\n",
    "model_names += xgb_cv_scores[0]\n",
    "model_results += xgb_cv_scores[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
